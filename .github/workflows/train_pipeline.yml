name: train-and-register

on:
  push:
    branches:
      - main
    paths:
      - 'backend/src/**'
      - 'backend/pipeline.yaml'
  workflow_dispatch:

jobs:
  train:
    runs-on: ubuntu-latest

    outputs:
      job_id: ${{ steps.submit.outputs.job_id }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install ML extension
        run: |
          az extension add -n ml

      - name: Azure Login
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Submit Pipeline Job
        id: submit
        run: |
          JOB_ID=$(az ml job create \
            --file backend/pipeline.yaml \
            --resource-group rg-nathan-mpops \
            --workspace-name ws-aaron-mlops \
            --query name -o tsv)

          echo "job_id=$JOB_ID" >> $GITHUB_OUTPUT

      - name: Stream Logs
        run: |
          az ml job stream \
            --name ${{ steps.submit.outputs.job_id }} \
            --resource-group rg-nathan-mpops \
            --workspace-name ws-aaron-mlops

  download:
    needs: train
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Azure Login
        uses: azure/login@v2
        with:
          creds: ${{ secrets.AZURE_CREDENTIALS }}

      - name: Download model
        uses: Azure/CLI@v2.2.0
        with:
          azcliversion: 2.80.0
          inlineScript: |
            az extension add -n ml -y
            az configure --defaults group=rg-nathan-mpops workspace=ws-aaron-mlops
            MODEL_VERSION=$(az ml model list --name spam-classifier --query "sort_by(@,&version)[-1].version" -o tsv)
            if [ -z "$MODEL_VERSION" ]; then
              echo "No registered versions found for spam-classifier"; exit 1; fi
            mkdir -p inference
            az ml model download \
              --name spam-classifier \
              --version "$MODEL_VERSION" \
              --download-path inference

      - name: Verify model contents
        run: |
          echo "Tree under inference:"; ls -R inference || true
          FOUND=$(find inference -type f -name MLmodel -print -quit)
          if [ -n "$FOUND" ]; then
            echo "Found MLflow MLmodel at: $FOUND"
          else
            echo "No MLflow MLmodel file found under inference."; exit 1
          fi

      # Move step no longer needed; download goes directly into inference/model

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: docker-config
          path: inference

    # (Optional deploy job removed for clarity; re-add when needed.)